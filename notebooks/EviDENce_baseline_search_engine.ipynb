{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline search engine for EviDENce\n",
    "\n",
    "Search strategy\n",
    "\n",
    "1. Collect corpus to perform search on\n",
    "2. Index documents in corpus\n",
    "3. Collect Keywords\n",
    "4. Construct query\n",
    "5. Perform search\n",
    "6. Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Collect corpus to perform search on**\n",
    "\n",
    "Our corpus consists of oral history accounts.\n",
    "These are broken up in text fragments of 100 lemmas and can be found in a zip folder on surfdrive:\n",
    "\n",
    "../Data/NR-teksts/EviDENce_NR_output/TargetSize100/Lemma_preserve_paragraph.zip\n",
    "\n",
    "*Make sure to extract the zip folder on high-level location on your computer a to avoid \"path-too-long\" error*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide path to extracted folder with lemma fragments\n",
    "root = os.path.join(os.sep,\"media\",\"sf_MartinedeVos\")\n",
    "search_dir = os.path.join(os.sep,root,\"lem_par_150\",\"lemma_preserve_paragraph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to alternative folder with lemma fragments\n",
    "surf = os.path.join(os.sep,root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Data\",\"NR-Teksts\",\"EviDENce_NR_output\")\n",
    "alt_search_dir = os.path.join(os.sep,surf,\"Size200\",\"fragmented_lemmas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Index all documents (i.e., lemma fragments) in the directory**\n",
    "\n",
    "* Create Schema\n",
    "* Add documents\n",
    "* Perform indexing\n",
    "\n",
    "_NB: this step only has to be run once, or when data is added or changed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_search import create_searchable_data\n",
    "\n",
    "# The creation of an index is only needed once; after that, opending the existing index is sufficient\n",
    "# in that case, the following line should be commented out\n",
    "\n",
    "#create_searchable_data(search_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Collect list of keywords from CEO-ECB mappings**\n",
    "\n",
    "Keywords are based on mappings from classes of the Circumstantial Event Ontology (CEO) on the ECB+ corpus\n",
    "\n",
    "Preprocessing entails:\n",
    "* express keywords as lemmas to ensure more effective matching \n",
    "* manually select keywords related to violence\n",
    "* translate selected keywords to Dutch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions use the google translate API \n",
    "# As this API has stability issues, there is a workaround in the next cell\n",
    "from baseline_search import create_lemma_list\n",
    "from baseline_search import eng_to_dutch_list\n",
    "\n",
    "mention_file =\"../data/MdV_selectedCEOECB.csv\"\n",
    "\n",
    "#en_mentions = create_lemma_list(mention_file)\n",
    "#nl_mentions = eng_to_dutch_list(en_mentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "mention_df = pd.read_csv(mention_file,sep=';',encoding = \"ISO-8859-1\")\n",
    "mention_df['Mention','CEO class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "prefab_file = \"../data/nl_mentions.csv\"\n",
    "prefab_mentions = pd.read_csv(prefab_file,sep=';',encoding = \"ISO-8859-1\")\n",
    "nl_mentions = list(prefab_mentions[\"Mention\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Construct query**\n",
    "\n",
    "* Sort keywords\n",
    "* Add double quotes to phrase queries\n",
    "* Concatenate all keywords into one query string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_search import quote_phrases\n",
    "\n",
    "nl_mention_list = list(set(nl_mentions))\n",
    "quoted_nl_mention_list = quote_phrases (nl_mention_list)\n",
    "nl_mention_query = \",\".join(quoted_nl_mention_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Perform search**\n",
    "\n",
    "Using whoosh library:\n",
    "\n",
    "* Define query parser: which schema, which search fields, AND/OR search\n",
    "* Define searcher: which scoring approach\n",
    "* Store info from results object in pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from whoosh import scoring\n",
    "from whoosh import qparser\n",
    "from whoosh.index import open_dir\n",
    "\n",
    "indexdir = os.path.join(os.sep,search_dir,\"indexdir\")\n",
    "ix = open_dir(indexdir)\n",
    "\n",
    "parser = qparser.QueryParser(\"content\", schema=ix.schema,group=qparser.OrGroup)\n",
    "my_query = parser.parse(nl_mention_query)\n",
    "\n",
    "cols_list = []\n",
    "titles_list = []\n",
    "\n",
    "with ix.searcher(weighting=scoring.TF_IDF()) as searcher:\n",
    "    results = searcher.search(my_query,limit=None, terms = True)\n",
    "    for res in results:\n",
    "        titles_list.append(res[\"title\"])\n",
    "        #row_dict = {}\n",
    "        col_dict = defaultdict(int)\n",
    "        hits = [term.decode('utf8')  for where,term in res.matched_terms()]\n",
    "        for hit in hits:\n",
    "            col_dict[hit]+= 1\n",
    "            #row_dict[hit] = row_dict.get(hit, 0) + 1  \n",
    "        cols_list.append(col_dict)\n",
    "\n",
    "#Create a dataframe for results of this search, i.e. with a limited set of keywords \n",
    "results_df = pd.DataFrame(cols_list)\n",
    "results_df.set_index([titles_list], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_805-813_lemma</th>\n",
       "      <td>dus dat zijn echt een huiselijk tafereel wat j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_814-822_lemma</th>\n",
       "      <td>je hebben kans dat er misschien wel tweehonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_823-832_lemma</th>\n",
       "      <td>en als hij dan dus de slang hebben localiseren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_833-839_lemma</th>\n",
       "      <td>en vanuit die kamp worden ze dus ook weer naar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_840-844_lemma</th>\n",
       "      <td>en dan hebben je daar weer een ellende en dan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_845-851_lemma</th>\n",
       "      <td>en dan komen de militair politie er weer bij ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_852-863_lemma</th>\n",
       "      <td>de stemming veranderen je worden dus eh ... ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_864-873_lemma</th>\n",
       "      <td>en dan zijn dus de ding gebeuren die dus moeil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_874-881_lemma</th>\n",
       "      <td>en dat staan ook in het boek van ' 60 jaar ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_882-891_lemma</th>\n",
       "      <td>en dat zijn eigenlijk nog niet hoeven gebeuren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_892-898_lemma</th>\n",
       "      <td>en worden u daar ook extra voorzichtig door , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_899-909_lemma</th>\n",
       "      <td>wat gebeuren er toen nou , wij moeten dus ... ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_90-99_lemma</th>\n",
       "      <td>ja ... je moeten in dienst , je zijn dienstpli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_910-918_lemma</th>\n",
       "      <td>en voor ons zijn er niets . er zijn geen schip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_919-926_lemma</th>\n",
       "      <td>en dan worden dat weer op_laden , brengen je w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_927-936_lemma</th>\n",
       "      <td>nou ja , goed , het zijn niet gebeuren hoelang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_937-947_lemma</th>\n",
       "      <td>en voelen u ook dreiging bij die post nee . ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_948-956_lemma</th>\n",
       "      <td>zeven maart weg_gaan de laat schip uit Soeraba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_957-964_lemma</th>\n",
       "      <td>ik hebben blijkbaar zeggen van : ' nou , ik te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_965-971_lemma</th>\n",
       "      <td>regelmatig met brief . maar ja , dat zijn één ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_972-981_lemma</th>\n",
       "      <td>en wat schrijven u naar huis ja , hoe je je vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_982-990_lemma</th>\n",
       "      <td>ja , waarom ook niet , ze hoeven ook niet alle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_991-1003_lemma</th>\n",
       "      <td>' en de groet van de buur . ' [ klein glim_lac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1648-1657_lemma</th>\n",
       "      <td>als u nu terug_kijken , wat voor invloed hebbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1658-1666_lemma</th>\n",
       "      <td>nou , dat doen ... dat zijn nog aan de gang hè...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1667-1673_lemma</th>\n",
       "      <td>ik hebben het zelf een keer gedaan in één van ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1674-1683_lemma</th>\n",
       "      <td>en waarom dat specifiek over van Manen uit_zoe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1684-1690_lemma</th>\n",
       "      <td>en de man die komen te overlijden , en toen wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1691-1698_lemma</th>\n",
       "      <td>dus al die mens die aanwezig zijn , die zijn m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_SiteFilms_Java_05_conversation_clipped_150_paragraph_1699-1707_lemma</th>\n",
       "      <td>of , als je officier zijn , dan kunnen je met ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_258-265_lemma</th>\n",
       "      <td>het zijn na de bevrijding dus . en hebben .. ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_266-274_lemma</th>\n",
       "      <td>maar kaal , ze worden niet scheren hoor , ze w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_275-280_lemma</th>\n",
       "      <td>en ik hebben één .. , een broer die eh gaan na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_281-290_lemma</th>\n",
       "      <td>zeggen , en eh wat .. , wat zijn u ... , wat z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_291-296_lemma</th>\n",
       "      <td>enorm ja . en we hebben wel ... , ik hebben da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_297-302_lemma</th>\n",
       "      <td>die dijk die bij ons het platteland in in_gaan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_303-311_lemma</th>\n",
       "      <td>zeg , maar zeg maar er schijnen dat er 40.000 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_312-319_lemma</th>\n",
       "      <td>ja , behalve degeen die dus direct onder_duike...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_320-330_lemma</th>\n",
       "      <td>&amp;amp;amp;amp;quot; wat jullie mee_maken hebben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_33-39_lemma</th>\n",
       "      <td>ja . en dat hebben ik dus niet doen en toen zi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_331-335_lemma</th>\n",
       "      <td>nee , niet naar de Coolsingel , naar de Veemar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_336-340_lemma</th>\n",
       "      <td>ik hebben hem hier ook weer zien hoor , want w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_341-346_lemma</th>\n",
       "      <td>en toen zijn het eigenlijk pas los_komen . en ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_347-354_lemma</th>\n",
       "      <td>wat zijn u emotie dan daarover of wat .. , wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_355-363_lemma</th>\n",
       "      <td>en dan de vloer van de kamer daaronder en daar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_364-367_lemma</th>\n",
       "      <td>mijn vader zijn chef van de Loon_afdeling , du...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_368-371_lemma</th>\n",
       "      <td>en dan eh .. , dan worden aan het end worden d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_372-377_lemma</th>\n",
       "      <td>en allemaal op die gewoon normaal rekenen_mach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_378-384_lemma</th>\n",
       "      <td>daar hebben ook Duitser in zitten de heel oorl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_40-44_lemma</th>\n",
       "      <td>en dan zeggen mijn .. , de jong_man , die laat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_45-51_lemma</th>\n",
       "      <td>en ik hebben ze dus horen , we zitten dus in ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_5-11_lemma</th>\n",
       "      <td>ik hebben in 1942 eind_examen doen , hetzelfde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_52-57_lemma</th>\n",
       "      <td>en het meisje wat ik net 7 maand kennen hebben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_58-62_lemma</th>\n",
       "      <td>en dan krijgen we ook te eten . en dat zijn he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_63-68_lemma</th>\n",
       "      <td>ik kunnen dat het beste wijzen naar de overkan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_69-74_lemma</th>\n",
       "      <td>en daar worden dus en daar zetten je dan , dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_75-81_lemma</th>\n",
       "      <td>de razzia hebben in dit stuk van Rotterdam nie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_82-89_lemma</th>\n",
       "      <td>en er zijn alleen een uitgang , je uit_kunnen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_90-92_lemma</th>\n",
       "      <td>dus eh ik denken dat .. , dat de hoe heten dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GV_DeJager_ReisvandeRazzia_interview_de_Bakker_conversation_clipped_150_paragraph_93-101_lemma</th>\n",
       "      <td>dus ze zijn er nooit zijn . of dat de reden zi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27065 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    0\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  dus dat zijn echt een huiselijk tafereel wat j...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  je hebben kans dat er misschien wel tweehonder...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en als hij dan dus de slang hebben localiseren...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en vanuit die kamp worden ze dus ook weer naar...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dan hebben je daar weer een ellende en dan ...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dan komen de militair politie er weer bij ,...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  de stemming veranderen je worden dus eh ... ja...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dan zijn dus de ding gebeuren die dus moeil...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dat staan ook in het boek van ' 60 jaar ext...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dat zijn eigenlijk nog niet hoeven gebeuren...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en worden u daar ook extra voorzichtig door , ...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  wat gebeuren er toen nou , wij moeten dus ... ...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  ja ... je moeten in dienst , je zijn dienstpli...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en voor ons zijn er niets . er zijn geen schip...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en dan worden dat weer op_laden , brengen je w...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  nou ja , goed , het zijn niet gebeuren hoelang...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en voelen u ook dreiging bij die post nee . ne...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  zeven maart weg_gaan de laat schip uit Soeraba...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  ik hebben blijkbaar zeggen van : ' nou , ik te...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  regelmatig met brief . maar ja , dat zijn één ...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en wat schrijven u naar huis ja , hoe je je vo...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  ja , waarom ook niet , ze hoeven ook niet alle...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  ' en de groet van de buur . ' [ klein glim_lac...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  als u nu terug_kijken , wat voor invloed hebbe...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  nou , dat doen ... dat zijn nog aan de gang hè...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  ik hebben het zelf een keer gedaan in één van ...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en waarom dat specifiek over van Manen uit_zoe...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  en de man die komen te overlijden , en toen wo...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  dus al die mens die aanwezig zijn , die zijn m...\n",
       "GV_SiteFilms_Java_05_conversation_clipped_150_p...  of , als je officier zijn , dan kunnen je met ...\n",
       "...                                                                                               ...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  het zijn na de bevrijding dus . en hebben .. ,...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  maar kaal , ze worden niet scheren hoor , ze w...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en ik hebben één .. , een broer die eh gaan na...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  zeggen , en eh wat .. , wat zijn u ... , wat z...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  enorm ja . en we hebben wel ... , ik hebben da...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  die dijk die bij ons het platteland in in_gaan...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  zeg , maar zeg maar er schijnen dat er 40.000 ...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  ja , behalve degeen die dus direct onder_duike...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  &amp;amp;amp;quot; wat jullie mee_maken hebben...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  ja . en dat hebben ik dus niet doen en toen zi...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  nee , niet naar de Coolsingel , naar de Veemar...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  ik hebben hem hier ook weer zien hoor , want w...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en toen zijn het eigenlijk pas los_komen . en ...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  wat zijn u emotie dan daarover of wat .. , wat...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en dan de vloer van de kamer daaronder en daar...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  mijn vader zijn chef van de Loon_afdeling , du...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en dan eh .. , dan worden aan het end worden d...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en allemaal op die gewoon normaal rekenen_mach...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  daar hebben ook Duitser in zitten de heel oorl...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en dan zeggen mijn .. , de jong_man , die laat...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en ik hebben ze dus horen , we zitten dus in ....\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  ik hebben in 1942 eind_examen doen , hetzelfde...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en het meisje wat ik net 7 maand kennen hebben...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en dan krijgen we ook te eten . en dat zijn he...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  ik kunnen dat het beste wijzen naar de overkan...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en daar worden dus en daar zetten je dan , dat...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  de razzia hebben in dit stuk van Rotterdam nie...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  en er zijn alleen een uitgang , je uit_kunnen ...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  dus eh ik denken dat .. , dat de hoe heten dat...\n",
       "GV_DeJager_ReisvandeRazzia_interview_de_Bakker_...  dus ze zijn er nooit zijn . of dat de reden zi...\n",
       "\n",
       "[27065 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with ix.searcher() as searcher:\n",
    "    index_dic = {doc['title']:[doc['textdata']] for doc in searcher.all_stored_fields()}   \n",
    "\n",
    "index_df = pd.DataFrame.from_dict(index_dic, orient='index')    \n",
    "index_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search results dataframe contains:\n",
    "* only those keywords that are found in documents\n",
    "* only those documents that have one or more keywords\n",
    "\n",
    "Combined dataframe contains: \n",
    "* all keywords, also those that are not present in documents\n",
    "* all documents, also those that have no keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe for all docs and keywords with empty values\n",
    "keywords_dic = {term:0 for term in quoted_nl_mention_list}\n",
    "list_docs = [doc['title'] for doc in ix.searcher().documents()] \n",
    "\n",
    "all_df = pd.DataFrame(keywords_dic, index = list_docs)\n",
    "\n",
    "# Create a dataframe for all docs and keywords with search results\n",
    "merged_df = results_df.combine_first(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently phrase queries are still broken up in separate search terms\n",
    "# this is shown by the surplus in columns in merged_df\n",
    "surplus = [col for col in merged_df if col not in all_df]\n",
    "# Remove these for now as a workaround; phrase queries should be fixed\n",
    "merged_df = merged_df.drop(columns = surplus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Process and describe results** \n",
    "\n",
    "* Describe general characteristics of baseline search\n",
    "    * Original corpus size\n",
    "    * Number of keywords\n",
    "    * csv with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = ix.searcher().documents() \n",
    "summed_docs = sum(1 for x in all_docs)\n",
    "\n",
    "summed_results =len(results_df.index)\n",
    "percent_hits = (summed_results/summed_docs)*100\n",
    "\n",
    "percent_keywords = (len(results_df.columns)/len(quoted_nl_mention_list))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_summary = os.path.join(root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Baseline summary.txt\")\n",
    "\n",
    "with open(report_summary, 'w') as file_handler:\n",
    "    # Add path to corpus\n",
    "    file_handler.write(\"Original corpus size: %s \\n\"%summed_docs)\n",
    "    file_handler.write(\"Number of snippets with keyword(s) present: %s \\n\"%summed_results)\n",
    "    file_handler.write(\"Percentage snippets with keywords(s) in corpus: %s \\n\"%percent_hits)\n",
    "    # Add path to keywords\n",
    "    file_handler.write(\"Total number of unique keywords found: %s \\n\"%len(results_df.columns))\n",
    "    file_handler.write(\"Percentage keywords found wrt to set used in query: %s \\n\"%percent_keywords)\n",
    "    file_handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw data\n",
    "report_raw_data = os.path.join(root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Baseline results.csv\")\n",
    "merged_df.to_csv(report_raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyze results\n",
    "    * nr keywords found per document\n",
    "    * nr keywords found per category\n",
    "    * nr hits found per keyword \n",
    "    * missed keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series for documents\n",
    "sum_docs = pd.Series(merged_df.sum(axis=1)).value_counts(sort=True)\n",
    "sum_docs = sum_docs.sort_index()\n",
    "\n",
    "p1 = sum_docs.plot(kind='bar')\n",
    "\n",
    "p1.set_title('Figure 1: Distribution of keywords (total nr) in the searched corpus')\n",
    "\n",
    "p1.get_figure().savefig(os.path.join(root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Hits_per_document.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series for keywords\n",
    "sum_keywords = pd.Series(merged_df.sum().iloc[:-1])\n",
    "\n",
    "sum_keywords = sum_keywords.sort_values(ascending=True)\n",
    "p2 = sum_keywords.iloc[-35:-1].plot(kind='barh', figsize = (12,10))\n",
    "\n",
    "p2.set_title('Figure 2: Total nr of hits for top 35 most frequent keywords')\n",
    "\n",
    "p2.get_figure().savefig(os.path.join(root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Freq_keywords.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store list of keywords that were not present in analyzed corpus\n",
    "report_missed_keywords = os.path.join(root,\"surfdrive\",\"Projects\", \"EviDENce\",\"Keywords not found in corpus.csv\")\n",
    "\n",
    "missed_keywords = sum_keywords[sum_keywords == 0]\n",
    "missed_keywords.to_csv(report_missed_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
